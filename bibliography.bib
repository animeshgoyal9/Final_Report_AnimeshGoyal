@article{Tampuu,
  author    = {Ardi Tampuu and
               Tambet Matiisen and
               Dorian Kodelja and
               Ilya Kuzovkin and
               Kristjan Korjus and
               Juhan Aru and
               Jaan Aru and
               Raul Vicente},
  title     = {Multiagent Cooperation and Competition with Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1511.08779},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.08779},
  archivePrefix = {arXiv},
  eprint    = {1511.08779},
  timestamp = {Mon, 13 Aug 2018 16:46:26 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/TampuuMKKKAAV15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Shao,
  title={A Survey of Deep Reinforcement Learning in Video Games},
  author={Kun Shao and Zhentao Tang and Yuanheng Zhu and Nannan Li and Dongbin Zhao},
  journal={ArXiv},
  year={2019},
  volume={abs/1912.10944}
}
 
@article{Stone,
author = {Stone, Peter and Veloso, Manuela},
year = {2000},
month = {05},
pages = {},
title = {Multiagent Systems: A Survey from a Machine Learning Perspective},
volume = {8},
journal = {Autonomous Robots},
doi = {10.1023/A:1008942012299}
} 

@article{Kulkarni,
  author    = {Tejas D. Kulkarni and
               Karthik Narasimhan and
               Ardavan Saeedi and
               Joshua B. Tenenbaum},
  title     = {Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction
               and Intrinsic Motivation},
  journal   = {CoRR},
  volume    = {abs/1604.06057},
  year      = {2016},
  url       = {http://arxiv.org/abs/1604.06057},
  archivePrefix = {arXiv},
  eprint    = {1604.06057},
  timestamp = {Mon, 13 Aug 2018 16:46:26 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KulkarniNST16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{SurveyandArticle,
  author    = {Pablo Hernandez{-}Leal and
               Bilal Kartal and
               Matthew E. Taylor},
  title     = {Is multiagent deep reinforcement learning the answer or the question?
               {A} brief survey},
  journal   = {CoRR},
  volume    = {abs/1810.05587},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.05587},
  archivePrefix = {arXiv},
  eprint    = {1810.05587},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-05587.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Leibo,
  author    = {Joel Z. Leibo and
               Vin{\'{\i}}cius Flores Zambaldi and
               Marc Lanctot and
               Janusz Marecki and
               Thore Graepel},
  title     = {Multi-agent Reinforcement Learning in Sequential Social Dilemmas},
  journal   = {CoRR},
  volume    = {abs/1702.03037},
  year      = {2017},
  url       = {http://arxiv.org/abs/1702.03037},
  archivePrefix = {arXiv},
  eprint    = {1702.03037},
  timestamp = {Mon, 13 Aug 2018 16:46:10 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/LeiboZLMG17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Mnih,
  author    = {Volodymyr Mnih and
               Koray Kavukcuoglu and
               David Silver and
               Alex Graves and
               Ioannis Antonoglou and
               Daan Wierstra and
               Martin A. Riedmiller},
  title     = {Playing Atari with Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1312.5602},
  year      = {2013},
  url       = {http://arxiv.org/abs/1312.5602},
  archivePrefix = {arXiv},
  eprint    = {1312.5602},
  timestamp = {Mon, 13 Aug 2018 16:47:42 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/MnihKSGAWR13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@INPROCEEDINGS{Kitano, author={H. {Kitano} and S. {Tadokoro} and I. {Noda} and H. {Matsubara} and T. {Takahashi} and A. {Shinjou} and S. {Shimada}}, booktitle={IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028)}, title={RoboCup Rescue: search and rescue in large-scale disasters as a domain for autonomous agents research}, year={1999}, volume={6}, number={}, pages={739-743 vol.6},}


@inproceedings{Morimoto,
author = {Visser, Arnoud and Ito, Nobuhiro and Kleiner, Alexander},
year = {2014},
month = {07},
pages = {},
title = {RoboCup Rescue Simulation Innovation Strategy},
volume = {8992},
journal = {Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)},
doi = {10.1007/978-3-319-18615-3-54}
}

@article{Lerer,
  author    = {Adam Lerer and
               Alexander Peysakhovich},
  title     = {Maintaining cooperation in complex social dilemmas using deep reinforcement
               learning},
  journal   = {CoRR},
  volume    = {abs/1707.01068},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.01068},
  archivePrefix = {arXiv},
  eprint    = {1707.01068},
  timestamp = {Mon, 13 Aug 2018 16:48:30 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/LererP17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@misc{stable-baselines,
  author = {Hill, Ashley and Raffin, Antonin and Ernestus, Maximilian and Gleave, Adam and Kanervisto, Anssi and Traore, Rene and Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai},
  title = {Stable Baselines},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/hill-a/stable-baselines}},
}

@misc{baselines,
  author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai and Zhokhov, Peter},
  title = {OpenAI Baselines},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openai/baselines}},
}

@article{RoboCup Rescue Simulator Manual,
    author = "Matthias,P.",
    title =       "RoboCup Rescue Technical Committee",
    journal =      "http://www.robocuprescue.org/docs/robocup-manual-vO-r4.pdf", 
    year =  "2000"
}

@article{Bilski,
    author =       "Bilski,A.,Kakuchi,S.",
    title =       "Kobe earthquake",
    journal =      "Maclean's", 
    year =         "1995"
}

@article{Abadi,
    author =       "Abadi,M.,Barham,P.,Chen,J.,Chen,Z.",
    title = "Tensorflow: A system for large scale machine learning",
    journal =      "In the 12th USENIX symposium on Operating system design and implementation(OSDI 16)", 
    year =         "2016", 
    pages = "265-283"
}

@article{Mao,
    author =       "Mao,H.,Alizadeh,M.,Menache,I.,Kandula,S.",
    title = "In the proceedings of the 15th ACM workshop onhot topics in networks",
    journal =      "HotNets", 
    year =         "2016", 
    pages = "50-56"
}

@article{Kavukcuoglu,
    author =       "Mnih,V.,Kavukcuoglu,K.,Silver,D.,Rusu,A.A.,&Petersen,S.",
    title =       "Human level control through deep reinforcement learning",
    journal =      "Nature", 
    year =         "2015", 
    pages = "529-533"
}

@article{Bansal,
    author =       "Bansal,T.,Pachocki,J.,Sidor,S.,Sutskever,I.,&Mordatch,I.",
    title =       "Emergent complexity via multiagent competition",
    journal =      "In International conference on machine learning", 
    year =         "2018"
}

@article{Weiner,
    author =       "Kleiman-Weiner, M., Ho,M.K., Austerweil, J.L., Littman, M.L., and Tenenbaum, J. B.",
    title =       "Coordinate to cooperate or compete: abstract goals and joint intentions in social interaction",
    journal =      "In Proceedings of the 38th annual conference of the cognitive science society", 
    year =         "2016", 
    pages =         "1679-1684"
}

@article{Cote,
    author =       "de Cote,E. M., Lazaric ,A. and Restelli,M. ",
    title =       "Learning to cooperate in multiagent soical dilemmas",
    journal =      "In Proceedings of the 5th international joint conference on autonomous agents and multiagent systems", 
    year =         "2006", 
    pages = "783-785"
}

@article{Raghu,
    author =       "Raghu,M. and Irpan,A. and Andreas,J. and Kleinberg,R. and Le,Q. and Kleinberg,J.",
    title =       "Can deep reinforcement learning solve Erdosâ€“Selfridge-spencer games?",
    journal =      "In Proceedings of the 35th international conference on machine learning", 
    year =         "2018"
}

@article{Nair,
    author =       "Nair, R. Tambe, M. Marsella, S",
    title =       "Task allocation in the rescue simulation domain: A short note",
    journal =      "RoboCup 2001: Robot Soccer World Cup V, volume 2377 of Lecture Notes in Computer Science", 
    year =         "2002",
    pages =        "751-754"
}

@article{Wooldridge,
    author =       "Wooldridge, M.",
    title =       "An Introduction to Multiagent Systems",
    journal =      ". John Wiley & Sons Ltd, second edition", 
    year =         "2009"
}

@article{Shao,
    author =       "Shao, K. Zhu, Y. Zhao, D",
    title =       "Starcraft micromanagement with reinforcement learning and curriculum transfer learning",
    journal =      "IEEE Transactions on Emerging Topics in Computational Intelligence", 
    year =         "2018"
}

@article{Jiang,
    author =       "Jiang, J. Lu, Z.",
    title =       "Learning attentional communication for multi-agent cooperation",
    journal =      "arXiv preprint arXiv: 1805.07733", 
    year =         "2018"
}

@book{Martinez,
    author    = "Martinez, I. and  Ojeda, D. and Zamora,E.,",
    title     = "Ambulance Decision Support Using Evolutionary Reinforcement Learning in RoboCup Rescue Simulation League",
    year      = "2007",
    publisher = "Robot Soccer World Cup X. RoboCup 2006",
    address   = "Berlin, Heidelberg"
}

@inproceedings{Visser2018RoboCupRS,
  title={RoboCup Rescue Simulation Machine Learning Workshop},
  author={Arnoud Visser and Luis G. Nardin and Sebastian Castro},
  year={2018}
}

@inproceedings{abdolmaleki,
author = {Abdolmaleki, Abbas and Movahedi, Mostafa and Salehi, Sajjad and Lau, Nuno and Reis, LuÃ­s},
year = {2011},
month = {10},
pages = {},
title = {A Reinforcement Learning Based Method for Optimizing the Process of Decision Making in Fire Brigade Agents},
volume = {7026},
journal = {Lecture notes in artificial intelligence},
doi = {10.1007/978-3-642-24769-9_25}
}

@article{Bitaghsir,
author = {Bitaghsir, Ali and Taghiyareh, Fattaneh and Simjour, Amirhossein and Mazloumian, Amin and Bostan, Babak},
year = {2019},
month = {12},
pages = {},
title = {UTEternity's Team Description : Layered Learning in RoboCup Rescue Simulation}
}

@inproceedings{Aghazadeh,
author = {Aghazadeh, Omid and Ahmad Sharbafi, Maziar and Haghighat, Abolfazl},
year = {2007},
month = {05},
pages = {409-416},
title = {Implementing Parametric Reinforcement Learning in Robocup Rescue Simulation},
volume = {5001},
doi = {10.1007/978-3-540-68847-1_42}
}

@inproceedings{gupta2017cooperative,
  title={Cooperative multi-agent control using deep reinforcement learning},
  author={Gupta, Jayesh K and Egorov, Maxim and Kochenderfer, Mykel},
  booktitle={International Conference on Autonomous Agents and Multiagent Systems},
  pages={66--83},
  year={2017},
  organization={Springer}
}

@article{Asghari,
author = {Asghari, Seyed Mohammad},
year = {2017},
title = {Deep Q-Learning(DQN) for Multi-agent Reinforcement Learning}
}

@article{Schulman,
author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
year = {2017},
title = {Proximal Policy Optimization Algorithms}
}

@misc{brockman2016openai,
  added-at = {2018-04-12T12:08:39.000+0200},
  author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  biburl = {https://www.bibsonomy.org/bibtex/2cdc8f927d6c8657ea82951a09e34161a/achakraborty},
  description = {[1606.01540] OpenAI Gym},
  interhash = {cfd0ba0b44eda9a3ca67480dfbf823a0},
  intrahash = {cdc8f927d6c8657ea82951a09e34161a},
  keywords = {2016 arxiv paper reinforcement-learning},
  note = {cite arxiv:1606.01540},
  timestamp = {2018-04-12T12:08:39.000+0200},
  title = {OpenAI Gym},
  url = {http://arxiv.org/abs/1606.01540},
  year = 2016
}

@ARTICLE{dota2,
       author = {{OpenAI} and {:} and {Berner}, Christopher and {Brockman}, Greg and
         {Chan}, Brooke and {Cheung}, Vicki and {D{\k{e}}biak}, Przemys{\l}aw and
         {Dennison}, Christy and {Farhi}, David and {Fischer}, Quirin and
         {Hashme}, Shariq and {Hesse}, Chris and {J{\'o}zefowicz}, Rafal and
         {Gray}, Scott and {Olsson}, Catherine and {Pachocki}, Jakub and
         {Petrov}, Michael and {Pond{\'e} de Oliveira Pinto}, Henrique and
         {Raiman}, Jonathan and {Salimans}, Tim and {Schlatter}, Jeremy and
         {Schneider}, Jonas and {Sidor}, Szymon and {Sutskever}, Ilya and
         {Tang}, Jie and {Wolski}, Filip and {Zhang}, Susan},
        title = "{Dota 2 with Large Scale Deep Reinforcement Learning}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
         year = "2019",
        month = "Dec",
          eid = {arXiv:1912.06680},
        pages = {arXiv:1912.06680},
archivePrefix = {arXiv},
       eprint = {1912.06680},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv191206680O},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{Starcraft2,
    author =       "Vinyals, O., Babuschkin, I., Czarnecki, W.M. et al.",
    title =        "Grandmaster level in StarCraft II using multi-agent reinforcement learning",
    journal =      "Nature",
    volume =       "575",
    number =       "350-354",
    DOI = "doi:10.1038/s41586-019-1724-z", 
    year =         "2019"
}

@InProceedings{Tadokoro,
author="Takahashi, Tomoichi
and Takeuchi, Ikuo
and Koto, Tetsuhiko
and Tadokoro, Satoshi
and Noda, Itsuki",
editor="Stone, Peter
and Balch, Tucker
and Kraetzschmar, Gerhard",
title="RoboCup-Rescue Disaster Simulator Architecture",
booktitle="RoboCup 2000: Robot Soccer World Cup IV",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="379--384",
abstract="RoboCup-Rescue project aims to simulate large urban disasters and rescue agents' activities. The simulator must support both simulation of heterogeneous agents such as fire fighters, victims' behaviors and interface to disaster's environments in the real world. RoboCup- Rescue simulator is a comprehensive urban disaster simulator into which a new disaster simulator or rescue agents can be easily plugged. In this paper, the simulator's specification, based on the Hanshin-Awaji Earthquake, and the simulator's architecture are described.",
isbn="978-3-540-45324-6"
}

@article{Barto,
    author =       "Sutton, Richard and Barto, Andrew",
    title =        "Reinforcement Learning, Second Edition: An Introduction",
    journal =      "MIT Press",
    volume =       "Second Edition",
    year =         "2018"
}

@article{MultiAgentLearning,
    author =       "Tuyls, k., Weiss, G.",
    title =        "Multiagent learning: Basics, challenges, and prospects",
    journal =      "AI Magazine",
    ages =          "41-52", 
    year =         "2012"
}

@article{Q-Learning,
    author =       "C.J.C.H, Watkins and P, Dayan",
    title =        " Q-learning. Machine Learning",
    volume =       "8",
    pages = "3-4", 
    year =         "1992"
}

@InProceedings{PPO,
    author = "Schulman,Jogn and  Levine,Sergey and Abbeel,Pieter and Jordan,Michael and  Moritz,Philipp",
    title =  " Trust region policy optimization",
    journal = "In Proceedings of the 32nd International Conference on Machine Learning
(ICML-15)", 
    year ="2015a",
    pages = "1889â€“1897"
}

@article{Independentlearners,
    author =       "Tan,M.",
    title =        " Multi-Agent Reinforcement Learning: Independent vs. Cooperative Agents",
    journal = "In Proceedings of the Tenth International Conference", 
    volume =       "8",
    pages = "330-337", 
    year =         "1993"
}
